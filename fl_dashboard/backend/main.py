from fastapi import FastAPI, HTTPException, UploadFile, File, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import shutil
import os
import json
import random
import hashlib
import datetime
from pathlib import Path
from sqlalchemy.orm import Session

from database import SessionLocal, init_db, HospitalUpload, InferenceLog

app = FastAPI(title="FL Simulation Dashboard API")

# Enable CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Paths - use absolute path to fl_results
import os
PROJECT_ROOT = Path(__file__).parent.parent.parent  # Go up from backend to codered5
FL_RESULTS_PATH = PROJECT_ROOT / "fl_results"
BLOCKCHAIN_PATH = FL_RESULTS_PATH / "blockchain_audit" / "audit_chain.json"

# Fallback if path doesn't exist
if not FL_RESULTS_PATH.exists():
    FL_RESULTS_PATH = Path("../../fl_results")
    BLOCKCHAIN_PATH = FL_RESULTS_PATH / "blockchain_audit/audit_chain.json"

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.on_event("startup")
def startup_event():
    init_db()

# --- Pydantic Models ---
class IoMTInput(BaseModel):
    heart_rate: float
    blood_pressure_sys: float
    blood_pressure_dia: float
    oxygen_saturation: float
    features: Optional[List[float]] = None

class InferenceResult(BaseModel):
    risk_score: float
    risk_level: str
    status: str

class SimulationResult(BaseModel):
    round: int
    auroc: Dict[str, float]
    weights: Dict[str, float]
    blockchain_block: int
    timestamp: str

# --- Routes ---

@app.get("/api/status")
def get_status():
    """Get high level dashboard stats"""
    rounds = len(list(FL_RESULTS_PATH.glob("round_*_aggregation.json")))
    blocks = 0
    
    if BLOCKCHAIN_PATH.exists():
        try:
            with open(BLOCKCHAIN_PATH) as f:
                chain = json.load(f)
                blocks = len(chain)
        except:
            pass
            
    return {
        "hospitals": 5,
        "round_current": rounds,
        "round_total": rounds,
        "total_samples": 27018,
        "privacy_budget": 5.0,
        "blockchain_blocks": blocks,
        "status": "Training Complete" if rounds >= 3 else "In Progress"
    }

@app.get("/api/rounds")
def get_rounds():
    """Get all round aggregation data"""
    data = []
    round_files = sorted(FL_RESULTS_PATH.glob("round_*_aggregation.json"))
    
    for p in round_files:
        try:
            with open(p) as f:
                data.append(json.load(f))
        except:
            pass
    return data

@app.get("/api/metrics")
def get_metrics():
    """Get pre/post FL metrics"""
    base_path = FL_RESULTS_PATH / "metrics"
    metrics = {}
    
    for stage in ["before_fl", "after_fl", "after_personalization"]:
        p = base_path / f"{stage}.json"
        if p.exists():
            with open(p) as f:
                metrics[stage] = json.load(f)
                
    return metrics

@app.get("/api/blockchain")
def get_blockchain():
    """Get full blockchain audit trail"""
    if BLOCKCHAIN_PATH.exists():
        with open(BLOCKCHAIN_PATH) as f:
            return json.load(f)
    return []

@app.post("/api/simulate_round")
def simulate_fl_round():
    """
    Simulate a new FL round:
    1. Generate new AUROC values (slight improvement)
    2. Create new round aggregation file
    3. Append block to blockchain
    4. Return results
    """
    # Determine current round
    existing_rounds = list(FL_RESULTS_PATH.glob("round_*_aggregation.json"))
    current_round = len(existing_rounds) + 1
    
    # Get previous round's AUROC as baseline
    prev_aurocs = {"A": 0.706, "B": 0.500, "C": 0.500, "D": 0.655, "E": 0.623}
    
    if existing_rounds:
        latest = sorted(existing_rounds)[-1]
        try:
            with open(latest) as f:
                prev_data = json.load(f)
                for client in prev_data.get("clients", []):
                    if client["id"] in prev_aurocs:
                        prev_aurocs[client["id"]] = client.get("auroc", prev_aurocs[client["id"]])
        except:
            pass
    
    # Simulate slight improvement
    new_aurocs = {}
    for h, prev in prev_aurocs.items():
        # Small random improvement (0-2%)
        improvement = random.uniform(0.005, 0.025) if prev < 0.85 else random.uniform(-0.01, 0.01)
        new_aurocs[h] = min(0.95, max(0.45, prev + improvement))
    
    # Sample counts (Aligned with QUICK_METRICS_SUMMARY.md)
    samples = {"A": 19601, "B": 1000, "C": 200, "D": 3000, "E": 3000}
    total_samples = sum(samples.values())
    
    # Calculate fairness weights
    weights = {}
    raw_weights = {}
    for h in new_aurocs:
        auroc_component = 0.6 * (new_aurocs[h] ** 2)
        data_component = 0.3 * (samples[h] / total_samples)
        domain_component = 0.1 * (0.5 if h in ["A", "D"] else 0.3)  # ECG hospitals get boost
        raw_weights[h] = auroc_component + data_component + domain_component
    
    total_weight = sum(raw_weights.values())
    for h in raw_weights:
        weights[h] = raw_weights[h] / total_weight
    
    timestamp = datetime.datetime.utcnow().isoformat()
    
    # Create round aggregation file
    round_data = {
        "round": current_round,
        "timestamp": timestamp,
        "num_clients": 5,
        "total_samples": total_samples,
        "clients": [
            {
                "id": h,
                "auroc": round(new_aurocs[h], 4),
                "samples": samples[h],
                "raw_weight": round(raw_weights[h], 4),
                "normalized_weight": round(weights[h], 4)
            }
            for h in ["A", "B", "C", "D", "E"]
        ]
    }
    
    round_file = FL_RESULTS_PATH / f"round_{current_round}_aggregation.json"
    with open(round_file, "w") as f:
        json.dump(round_data, f, indent=2)
    
    # Append to blockchain
    blockchain = []
    if BLOCKCHAIN_PATH.exists():
        try:
            with open(BLOCKCHAIN_PATH) as f:
                blockchain = json.load(f)
        except:
            pass
    
    prev_hash = blockchain[-1]["hash"] if blockchain else "0000000000000000"
    
    new_block = {
        "block_index": len(blockchain),
        "timestamp": timestamp,
        "block_type": "FL_ROUND",
        "round_number": current_round,
        "data": {
            "aggregation_method": "FedProxFairness",
            "num_clients": 5,
            "total_samples": total_samples,
            "client_weights": [
                {"id": h, "auroc": round(new_aurocs[h], 4), "normalized_weight": round(weights[h], 4)}
                for h in ["A", "B", "C", "D", "E"]
            ],
            "fairness_formula": "0.6*AUROC¬≤ + 0.3*samples + 0.1*domain_relevance",
            "weights_sum": 1.0,
            "verification": {
                "weights_normalized": True,
                "all_clients_present": True
            }
        },
        "previous_hash": prev_hash
    }
    
    # Compute hash
    block_string = json.dumps(new_block, sort_keys=True)
    new_block["hash"] = hashlib.sha256(block_string.encode()).hexdigest()
    
    blockchain.append(new_block)
    
    with open(BLOCKCHAIN_PATH, "w") as f:
        json.dump(blockchain, f, indent=2)
    
    return {
        "success": True,
        "round": current_round,
        "auroc": {h: round(v, 4) for h, v in new_aurocs.items()},
        "weights": {h: round(v, 4) for h, v in weights.items()},
        "blockchain_block": len(blockchain) - 1,
        "timestamp": timestamp,
        "message": f"Round {current_round} simulated successfully. Block {len(blockchain)-1} committed."
    }

@app.post("/api/hospital/{hospital_id}/upload")
async def upload_file(hospital_id: str, file: UploadFile = File(...), db: Session = Depends(get_db)):
    """Handle hospital data upload"""
    upload_dir = Path(f"uploads/{hospital_id}")
    upload_dir.mkdir(parents=True, exist_ok=True)
    
    file_location = upload_dir / file.filename
    with open(file_location, "wb+") as file_object:
        shutil.copyfileobj(file.file, file_object)
        
    db_entry = HospitalUpload(
        hospital_id=hospital_id, 
        filename=file.filename,
        metadata_info={"size": file.size}
    )
    db.add(db_entry)
    db.commit()
    
    return {"info": f"file '{file.filename}' saved at '{file_location}'"}

@app.post("/api/inference/hospital_b", response_model=InferenceResult)
def run_inference(data: IoMTInput):
    """Run inference for Hospital B (Emergency Prediction)"""
    risk_score = 0.1
    
    if data.heart_rate > 100 or data.heart_rate < 55: 
        risk_score += 0.35
    if data.oxygen_saturation < 94: 
        risk_score += 0.4
    if data.blood_pressure_sys > 160: 
        risk_score += 0.2
    
    risk_score += random.uniform(-0.05, 0.05)
    risk_score = max(0.0, min(0.95, risk_score))
    
    level = "Stable ‚úÖ"
    if risk_score > 0.6: level = "Critical üö®"
    elif risk_score > 0.35: level = "Warning ‚ö†Ô∏è"
    
    return {
        "risk_score": risk_score,
        "risk_level": level,
        "status": "Inference Successful (Hospital B Personalized Model)"
    }

@app.get("/api/download/all")
def download_artifacts():
    """Zip and download FL results"""
    zip_name = "fl_simulation_artifacts"
    shutil.make_archive(zip_name, 'zip', FL_RESULTS_PATH)
    return FileResponse(f"{zip_name}.zip", media_type='application/zip', filename=f"{zip_name}.zip")
